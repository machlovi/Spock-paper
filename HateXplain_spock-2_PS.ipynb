{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/machlovi/Spock-paper/blob/main/X_hate_and_offensive_data_combine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdBpcROn7EF-"
   },
   "source": [
    "# This file uses HateXplain data\n",
    "We are initailizing 2 vector space for 3(after convertingtheminto 2 class) classes in this code. Main idea is to visualize how we can separate words related to each classes in the given space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4UYfxZaZz6j8",
    "outputId": "09a73fe3-70ee-4cca-c198-fafbeda639f7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! apt-get install git\n",
    "# !pip install --upgrade protobuf\n",
    "# !pip install --upgrade jupyterlab-server google-api-core cached-path alchemy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj4pk2f97ALa"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7fS4-4j6y_h",
    "outputId": "6b5de3d8-1951-4e39-8a5e-2a5759d5f38d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/naseem_fordham/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/naseem_fordham/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/home/naseem_fordham/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\",20)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "from transformers import TFAutoModel, BertTokenizerFast, BertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks as cb\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "import keras\n",
    "from keras.layers import Input, Concatenate, Flatten, Embedding, Dense, Dropout, LSTM\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Lambda\n",
    "from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To display full column and rows values\n",
    "# pd.set_option('display.max_column', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_seq_items', None)\n",
    "# pd.set_option('display.max_colwidth', 500)\n",
    "# pd.set_option('expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  Looking for GPU using by this kernel\n",
    "              \n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # Specify the GPU you want to use\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "# Check if TensorFlow is using GPU\n",
    "if tf.test.gpu_device_name():\n",
    "    print(\"Default GPU Device: {}\".format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"No GPU devices found. TensorFlow is using CPU.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwO1A2SdOWyR"
   },
   "source": [
    "### Hate and offesive data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vkjUmWVzTNN_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text,                                                               # text is a word string ex. 'rahul in ny'\n",
    "                      punctuations = r'''!()-[]{};:'\"\\,<>./?@#$%^&*_“~='ã¶``''',\n",
    "                      stop_words = set(stopwords.words(\"english\"))) -> list:\n",
    "\n",
    "        '''\n",
    "        A method to preprocess text\n",
    "\n",
    "        '''\n",
    "\n",
    "        for x in text.lower():\n",
    "            if x in punctuations:\n",
    "                text = text.replace(x,\"\")\n",
    "\n",
    "        # removing words that have numbers in them\n",
    "        text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "        # remove digits\n",
    "        text = re.sub(r'[0-9]+', ' ', text)\n",
    "\n",
    "        # clean the whitespaces\n",
    "\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "\n",
    "\n",
    "        # convert all text to a list\n",
    "\n",
    "        # text = text.split(' ').  # uncomment if list required\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                   u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                   u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                   u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "                                   u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "                                   u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                                   u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                                   u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                                   u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                                   u\"\\U00002702-\\U000027B0\"  # Dingbat symbols\n",
    "                                   u\"\\U000024C2-\\U0001F251\" \n",
    "                                   \"]+\", flags=re.UNICODE)\n",
    "        text = emoji_pattern.sub(r'', text)\n",
    "\n",
    "        # lowercase eth\n",
    "\n",
    "        text = text.lower()\n",
    "\n",
    "\n",
    "        # drop the stop words\n",
    "\n",
    "\n",
    "\n",
    "        # add the tags\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HateOffensive data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lp7FNeAE7M-s"
   },
   "source": [
    "https://github.com/t-davidson/hate-speech-and-offensive-language/tree/master/data#Data import\n",
    "\n",
    "Data Source \"https://github.com/t-davidson/33 ##\n",
    "hate-speech-and-offensive-language/blob/master/data/readme.md\"\n",
    "'''hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "class = class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither'''\n",
    "In this case 0 non-toxic and 1 -toxic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #loading hate ofefsive data and converting it into 2 class data as toxic and non-toxic\n",
    "# df_data1=pd.read_csv(\"/home/naseem_fordham/Spock-paper/data/labeled_data.csv\")\n",
    "# dataframe=df_data1[['class','tweet']]\n",
    "# dataframe=dataframe.dropna()\n",
    "# dataframe.reset_index(drop=True)\n",
    "# dataframe['class'].unique()\n",
    "\n",
    "# # #initially we have 3 classes and now we are converting them into binary class\n",
    "\n",
    "# dataframe[\"class\"] = dataframe[\"class\"].apply(lambda x: 1.0 if x in [0., 1.] else 0.0)\n",
    "# # HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "\n",
    "# dataframe[\"tweet\"] = dataframe[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "# dataframe = dataframe.sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "# # dataframe=HateXplain\n",
    "# dataframe['class'].unique()\n",
    "# # dataframe.tail(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-8-49616225c1b3&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'dataframe'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-8-49616225c1b3>\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'dataframe'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataframe['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgqQcCnzJ9_i",
    "tags": []
   },
   "source": [
    "### Xhate-999 data set\n",
    "Class 1 hate, Class 0 non-hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "AgABCT3f-VSJ",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "# # Use this part for single file\n",
    "# # Define the path to your text file\n",
    "# file_path = \"/gdrive/MyDrive/SPOCK/Dataset/xhate-main/train/XHate999-EN-Gao-train.txt\"\n",
    "\n",
    "# # Initialize empty lists to store data\n",
    "# tweets = []\n",
    "# labels = []\n",
    "\n",
    "# # Read the file line by line\n",
    "# with open(file_path, 'r') as file:\n",
    "#     for line in file:\n",
    "#         # Split the line into text and label using the last character\n",
    "#         line = line.strip()  # Remove leading/trailing whitespace\n",
    "#         text = line[:-2].strip()  # Extract text (excluding the last character)\n",
    "#         label = line[-1]  # Extract the label (as an integer)\n",
    "\n",
    "#         # Append data to lists\n",
    "#         tweets.append(text)\n",
    "#         labels.append(label)\n",
    "\n",
    "# # Create a DataFrame from the lists\n",
    "# df = pd.DataFrame({'Text': tweets, 'Label': labels})\n",
    "# df.drop(0,inplace=True)\n",
    "\n",
    "# # Display the DataFrame\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sp_S78bwGI6h",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# # Define the directory path where your text files are located\n",
    "# directory_path = \"/gdrive/MyDrive/SPOCK/Dataset/xhate-main/train\"\n",
    "\n",
    "# # Initialize empty lists to store data\n",
    "# tweets = []\n",
    "# labels = []\n",
    "\n",
    "# # Loop through all text files in the specified directory\n",
    "# for filename in glob.glob(os.path.join(directory_path, '*.txt')):\n",
    "#     with open(filename, 'r') as file:\n",
    "\n",
    "#       for line in file:\n",
    "#           # Split the line into text and label using the last character\n",
    "#           line = line.strip()  # Remove leading/trailing whitespace\n",
    "#           text = line[:-2].strip()  # Extract text (excluding the last character)\n",
    "#           label = line[-1]  # Extract the label (as an integer)\n",
    "\n",
    "#           # Append data to lists\n",
    "#           tweets.append(text)\n",
    "#           labels.append(label)\n",
    "\n",
    "# # Create a DataFrame from the lists\n",
    "# df = pd.DataFrame({'tweet': tweets, 'class': labels})\n",
    "# df.drop(0,inplace=True)\n",
    "\n",
    "\n",
    "# df['class']=pd.to_numeric(df['class'], errors='coerce')\n",
    "# df['class'].fillna(0, inplace=True)\n",
    "# df['class']=df['class'].astype(int)\n",
    "# df_hate2=df[df['class']==1]\n",
    "# df_nonhate2=df[df['class']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKc-jTjJSzoM"
   },
   "source": [
    "##Combing hatespeech and xhate data for hate/offensive class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HateXplain Dataset\n",
    "Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this work, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (i.e., hate, offensive or normal), the target community (i.e., the community that has been the victim of hate speech/offensive speech in the post), and the rationales\n",
    "\n",
    "In this case we are using Toxic and Non-toxic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Here we have implenting attenstion score for HateXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-121834d65971>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['label']='non_toxic'\n",
      "<ipython-input-11-121834d65971>:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['leng']=df_n['post_tokens'].apply(lambda x: len(x))\n",
      "<ipython-input-11-121834d65971>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['rationales'] = df_n['leng'].apply(lambda length: [1/length] *length )\n",
      "<ipython-input-11-121834d65971>:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales1']=df_ho['rationales'].apply(lambda x: x[0])\n",
      "<ipython-input-11-121834d65971>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales2']=df_ho['rationales'].apply(lambda x: x[1])\n",
      "<ipython-input-11-121834d65971>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['rationales3']=df_ho['rationales'].apply(lambda x: x[2:3])\n",
      "<ipython-input-11-121834d65971>:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['sum_result'] = df_ho.apply(lambda row: [a + b + c for a, b, c in zip(row['rationales1'], row['rationales2'],row['rationales1'])], axis=1)\n",
      "<ipython-input-11-121834d65971>:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ho['mean']=df_ho['sum_result'].apply(lambda x: [val /3 for val in x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rationales</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user i am bit confused coz chinese ppl can not...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>[0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nogs jews and dykes how enriching</td>\n",
       "      <td>[1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>guilty until proven innocent unless you are a ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.666...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tired i can not support abortion from a moral ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>number number percent of brits think multicult...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all of my exes were cute but they were hoes i ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user condoning drug use not kike at all thanks...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>toxic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  user i am bit confused coz chinese ppl can not...   \n",
       "1  this bitch in whataburger eating a burger with...   \n",
       "2  laura loomer raped me while screaming at me in...   \n",
       "3  and this is why i end up with nigger trainee d...   \n",
       "4                  nogs jews and dykes how enriching   \n",
       "5  guilty until proven innocent unless you are a ...   \n",
       "6  tired i can not support abortion from a moral ...   \n",
       "7  number number percent of brits think multicult...   \n",
       "8  all of my exes were cute but they were hoes i ...   \n",
       "9  user condoning drug use not kike at all thanks...   \n",
       "\n",
       "                                          rationales  class  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "1  [0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...  toxic  \n",
       "4      [1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]  toxic  \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.666...  toxic  \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  toxic  \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...  toxic  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"/home/naseem_fordham/Spock-paper/data/Hate_Xplain.json\")\n",
    "df_t=df.T\n",
    "\n",
    "df = pd.read_json(\"/home/naseem_fordham/Spock-paper/data/Hate_Xplain.json\")\n",
    "df_t=df.T\n",
    "#  extracting each label from nester list\n",
    "df_t['annotators0']=df_t['annotators'].apply(lambda x: x[0]['label'])\n",
    "df_t['annotators1']=df_t['annotators'].apply(lambda x: x[1]['label'])\n",
    "df_t['annotators2']=df_t['annotators'].apply(lambda x: x[2]['label'])\n",
    "\n",
    "# laeblling\n",
    "\n",
    "df_t['annotators0']=df_t['annotators0'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "df_t['annotators1']=df_t['annotators1'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "df_t['annotators2']=df_t['annotators2'].apply(lambda x: 0.0 if x == \"hatespeech\" else (1.0 if x == \"offensive\" else 2.0))\n",
    "\n",
    "# dropping some unnecessary columns\n",
    "df_t.drop(['post_id','annotators'],axis=1,inplace=True)\n",
    "\n",
    "# sperating non_toxic\n",
    "df_n = df_t[((df_t['annotators0'] == 2.0) & (df_t['annotators1'] == 2.0) & (df_t['annotators2'] == 2.0)) | (df_t['rationales'].apply(lambda x: len(x) == 0))]\n",
    "df_n['label']='non_toxic'\n",
    "\n",
    "#Generating rationles values for non-rationles by deving the 1 by the total length\n",
    "df_n['leng']=df_n['post_tokens'].apply(lambda x: len(x))\n",
    "df_n['rationales'] = df_n['leng'].apply(lambda length: [1/length] *length )\n",
    "\n",
    "\n",
    "#separating toxic\n",
    "df_ho = df_t[~df_t.index.isin(df_n.index)]\n",
    "\n",
    "\n",
    "# taking mean of rationales\n",
    "df_ho['rationales1']=df_ho['rationales'].apply(lambda x: x[0])\n",
    "df_ho['rationales2']=df_ho['rationales'].apply(lambda x: x[1])\n",
    "df_ho['rationales3']=df_ho['rationales'].apply(lambda x: x[2:3])\n",
    "\n",
    "df_ho['sum_result'] = df_ho.apply(lambda row: [a + b + c for a, b, c in zip(row['rationales1'], row['rationales2'],row['rationales1'])], axis=1)\n",
    "df_ho['mean']=df_ho['sum_result'].apply(lambda x: [val /3 for val in x])\n",
    "\n",
    "df_toxic=df_ho[['post_tokens','mean']].rename(columns={'mean':'rationales'})\n",
    "df_toxic['label']='toxic'\n",
    "\n",
    "df_combine = pd.concat([df_toxic,df_n[['post_tokens','label','rationales']]]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_combine[\"post_tokens\"].values\n",
    "for i in range(len(df_combine[\"post_tokens\"])):\n",
    "    df_combine[\"post_tokens\"][i] = \" \".join(df_combine[\"post_tokens\"][i])\n",
    "\n",
    "df_combine[\"post_tokens\"] = df_combine[\"post_tokens\"].apply(lambda x : text_preprocessing(x))\n",
    "df_combine.rename(columns={\"post_tokens\":\"tweet\",\"label\":\"class\"},inplace=True)\n",
    "# dataframe=df_combine.sample(frac = 1).reset_index(drop = True)\n",
    "df_combine.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def softmax(x):\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "#     return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# # Apply softmax to the 'numbers' column\n",
    "# dataframe['softmax_numbers'] = dataframe['rationales'].apply(softmax)\n",
    "\n",
    "# dataframe.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe=df_combine.copy()\n",
    "\n",
    "dataframe[\"tweet\"] = dataframe[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "dataframe[\"class\"] = dataframe[\"class\"].apply(lambda x: 1.0 if x ==\"non_toxic\" else 0.0)\n",
    "\n",
    "\n",
    "Temprature=0.4\n",
    "dataframe['rationales_T']= dataframe['rationales'].apply(lambda x: [val /Temprature for val in x])\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    softmax_values= e_x / e_x.sum(axis=0)\n",
    "    return np.round(softmax_values, 3)\n",
    "\n",
    "# Apply softmax to the 'numbers' column\n",
    "dataframe['softmax_numbers'] = dataframe['rationales'].apply(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>rationales</th>\n",
       "      <th>class</th>\n",
       "      <th>rationales_T</th>\n",
       "      <th>softmax_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user i am bit confused coz chinese ppl can not...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.034, 0.034, 0.034, 0.034, 0.034, 0.034, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>[0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 1.6666666666666665, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.038, 0.074, 0.038, 0.038, 0.038, 0.038, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.032, 0.032, 0.032, 0.032, 0.032, 0.032, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5, ...</td>\n",
       "      <td>[0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nogs jews and dykes how enriching</td>\n",
       "      <td>[1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[2.5, 2.5, 1.6666666666666665, 2.5, 0.0, 0.0]</td>\n",
       "      <td>[0.225, 0.225, 0.161, 0.225, 0.083, 0.083]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>guilty until proven innocent unless you are a ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.666...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 1.6666666666666665, 1.666...</td>\n",
       "      <td>[0.035, 0.035, 0.035, 0.035, 0.067, 0.067, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tired i can not support abortion from a moral ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>number number percent of brits think multicult...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>all of my exes were cute but they were hoes i ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.043, 0.043, 0.043, 0.043, 0.043, 0.043, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user condoning drug use not kike at all thanks...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 2.5, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.073, 0.073, 0.073, 0.073, 0.073, 0.198, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  user i am bit confused coz chinese ppl can not...   \n",
       "1  this bitch in whataburger eating a burger with...   \n",
       "2  laura loomer raped me while screaming at me in...   \n",
       "3  and this is why i end up with nigger trainee d...   \n",
       "4                  nogs jews and dykes how enriching   \n",
       "5  guilty until proven innocent unless you are a ...   \n",
       "6  tired i can not support abortion from a moral ...   \n",
       "7  number number percent of brits think multicult...   \n",
       "8  all of my exes were cute but they were hoes i ...   \n",
       "9  user condoning drug use not kike at all thanks...   \n",
       "\n",
       "                                          rationales  class  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "1  [0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...    0.0   \n",
       "4      [1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]    0.0   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.666...    0.0   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...    0.0   \n",
       "\n",
       "                                        rationales_T  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 1.6666666666666665, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5, ...   \n",
       "4      [2.5, 2.5, 1.6666666666666665, 2.5, 0.0, 0.0]   \n",
       "5  [0.0, 0.0, 0.0, 0.0, 1.6666666666666665, 1.666...   \n",
       "6  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "7  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "8  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "9  [0.0, 0.0, 0.0, 0.0, 0.0, 2.5, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                     softmax_numbers  \n",
       "0  [0.034, 0.034, 0.034, 0.034, 0.034, 0.034, 0.0...  \n",
       "1  [0.038, 0.074, 0.038, 0.038, 0.038, 0.038, 0.0...  \n",
       "2  [0.032, 0.032, 0.032, 0.032, 0.032, 0.032, 0.0...  \n",
       "3  [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.0...  \n",
       "4         [0.225, 0.225, 0.161, 0.225, 0.083, 0.083]  \n",
       "5  [0.035, 0.035, 0.035, 0.035, 0.067, 0.067, 0.0...  \n",
       "6  [0.013, 0.013, 0.013, 0.013, 0.013, 0.013, 0.0...  \n",
       "7  [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.0...  \n",
       "8  [0.043, 0.043, 0.043, 0.043, 0.043, 0.043, 0.0...  \n",
       "9  [0.073, 0.073, 0.073, 0.073, 0.073, 0.198, 0.0...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "      <th>softmax_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user i am bit confused coz chinese ppl can not...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.034, 0.034, 0.034, 0.034, 0.034, 0.034, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.038, 0.074, 0.038, 0.038, 0.038, 0.038, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.032, 0.032, 0.032, 0.032, 0.032, 0.032, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nogs jews and dykes how enriching</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.225, 0.225, 0.161, 0.225, 0.083, 0.083]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20143</th>\n",
       "      <td>it a bitch to find i accidently opened it how ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.031, 0.031, 0.031, 0.031, 0.031, 0.031, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20144</th>\n",
       "      <td>anybody notice anything strange on gab like so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.026, 0.026, 0.026, 0.026, 0.026, 0.026, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20145</th>\n",
       "      <td>graph straftaten gegen die sexuelle selbstbest...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.037, 0.037, 0.037, 0.037, 0.037, 0.037, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20146</th>\n",
       "      <td>an afghani immigrant once told me that in afgh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.023, 0.023, 0.023, 0.023, 0.023, 0.023, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20147</th>\n",
       "      <td>was macht der moslem wenn der zion gegen seine...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.043, 0.043, 0.043, 0.043, 0.043, 0.043, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  class  \\\n",
       "0      user i am bit confused coz chinese ppl can not...    0.0   \n",
       "1      this bitch in whataburger eating a burger with...    0.0   \n",
       "2      laura loomer raped me while screaming at me in...    0.0   \n",
       "3      and this is why i end up with nigger trainee d...    0.0   \n",
       "4                      nogs jews and dykes how enriching    0.0   \n",
       "...                                                  ...    ...   \n",
       "20143  it a bitch to find i accidently opened it how ...    1.0   \n",
       "20144  anybody notice anything strange on gab like so...    1.0   \n",
       "20145  graph straftaten gegen die sexuelle selbstbest...    1.0   \n",
       "20146  an afghani immigrant once told me that in afgh...    1.0   \n",
       "20147  was macht der moslem wenn der zion gegen seine...    1.0   \n",
       "\n",
       "                                         softmax_numbers  \n",
       "0      [0.034, 0.034, 0.034, 0.034, 0.034, 0.034, 0.0...  \n",
       "1      [0.038, 0.074, 0.038, 0.038, 0.038, 0.038, 0.0...  \n",
       "2      [0.032, 0.032, 0.032, 0.032, 0.032, 0.032, 0.0...  \n",
       "3      [0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.0...  \n",
       "4             [0.225, 0.225, 0.161, 0.225, 0.083, 0.083]  \n",
       "...                                                  ...  \n",
       "20143  [0.031, 0.031, 0.031, 0.031, 0.031, 0.031, 0.0...  \n",
       "20144  [0.026, 0.026, 0.026, 0.026, 0.026, 0.026, 0.0...  \n",
       "20145  [0.037, 0.037, 0.037, 0.037, 0.037, 0.037, 0.0...  \n",
       "20146  [0.023, 0.023, 0.023, 0.023, 0.023, 0.023, 0.0...  \n",
       "20147  [0.043, 0.043, 0.043, 0.043, 0.043, 0.043, 0.0...  \n",
       "\n",
       "[20148 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=dataframe[['tweet','class','softmax_numbers']]\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # HateXplain Dataset converting into binary class\n",
    "# HateXplain = pd.read_csv('/home/naseem_fordham/Spock-paper/data/Hate_Xplain.csv')\n",
    "# HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "# # HateXplain[\"label\"] = HateXplain[\"label\"].apply(lambda x: 1.0 if x in [\"hatespeech\", \"offensive\"] else 0.0)\n",
    "\n",
    "# HateXplain[\"text\"] = HateXplain[\"text\"].apply(lambda x : text_preprocessing(x))\n",
    "# HateXplain = HateXplain.sample(frac = 1).reset_index(drop = True)\n",
    "# HateXplain.rename(columns={\"text\":\"tweet\",\"label\":\"class\"},inplace=True)\n",
    "# dataframe=HateXplain\n",
    "# dataframe['class'].unique()\n",
    "# dataframe.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "nYkMXWiRRL_p",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_hate_combine=pd.concat([df_hate,df_hate2]).reset_index(drop=True)\n",
    "# df_nonhat_combine=pd.concat([df_peace,df_nonhate2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "2O2ELyIrWKEx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_hate_combine[\"tweet\"] = df_hate_combine[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "# df_nonhat_combine[\"tweet\"] = df_nonhat_combine[\"tweet\"].apply(lambda x : text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "LMfpk0-oRBjF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe=pd.concat([df_hate_combine ,df_nonhat_combine]).reset_index(drop=True)\n",
    "# dataframe.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine HateXplain, Xhate and offensive speech data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# dataframe=pd.read_csv(\"combine_data.csv\")\n",
    "# dataframe=pd.concat([dataframe ,HateXplain]).reset_index(drop=True)\n",
    "\n",
    "# dataframe.dropna(inplace=True)\n",
    "# dataframe.to_csv(\"3dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe=pd.read_csv(\"3dataset.csv\")\n",
    "\n",
    "# dataframe.dropna(inplace=True)\n",
    "# dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "-Y5XnqHVWi9T",
    "outputId": "868f2ad5-0f5c-41c8-b705-f1b3ad8f012f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# token lengths distribution in the dataset\n",
    "token_lengths = [len(i.split()) for i in dataframe[\"tweet\"]]\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(token_lengths,bins = 30,edgecolor=\"black\")\n",
    "plt.xticks(ticks = np.linspace(10,100,11))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "0AxSspAzSE6A",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe[dataframe['class']==1].shape,dataframe[dataframe['class']==0].shape,dataframe[dataframe['class']==2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQEmSl2aS7_T"
   },
   "source": [
    "# Training and validation set\n",
    "We can also consider token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xA2mJ75ARWBv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe[\"token_length\"] = token_lengths\n",
    "# dataframe = dataframe.loc[dataframe[\"token_length\"] <= 25, :].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6M-IQ2ZyYVwb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# token_length 128, seems a good fit for data\n",
    "\n",
    "# split training and validation data\n",
    "train_df, val_df = train_test_split(dataframe, test_size= 0.20, stratify= dataframe[\"class\"], random_state = 40)\n",
    "\n",
    "# val_df,   test_df   = train_test_split(temp_df, test_size= 0.80, stratify= temp_df[\"class\"],random_state = 47)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df   = val_df.reset_index(drop  = True)\n",
    "# test_df  = test_df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9qCr_5aTbOn"
   },
   "source": [
    "#Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4030, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "referenced_widgets": [
      "570b9a872e614e0eab6618f306be7306",
      "34e574772e8b4f81bc7e02e8ebaeb258",
      "1cf66f2a8c5f49ce98d59dae5186298d",
      "71f100b04c964a1bbde06c537f483ed7",
      "9e1caf8b23fb4eb1976f808269d1dd3e",
      "3258d106659040dfb7ffea47c017ed38",
      "f9a2caba063b4a4f98ad258044d012fb",
      "dfd44792f624499b87bd768836016e88",
      "ae841edad05b4ef9b4308308d6683fa3",
      "34bbd1edf06c4a9194bd27eaeeee32b2",
      "ea850e74cb6a4121a456578b29ce7955",
      "d69dfd21bce04204b3220b71b4d4a968",
      "4914d10c0f354e178de66dc11449e26a",
      "f554ec9fe80a408680aa7b0a1c6837ac",
      "f4ec333b7c654876a6caad010e88c203",
      "cfe933364a3147368660f5463f1e5a29",
      "f7998e50af804d66b6af0f26b5588255",
      "4fa52eecbe8a4ba38ef969fd1cf48cfd",
      "3c294ab0d9a648f39ea3f3fb7dd08c3c",
      "31914a14cfa243388f43a02da4db24b6",
      "69d90bdca5174dfb91f5cf124884095e",
      "123641d1426541fba838576dff7f6082",
      "71d0c2b02f0c4a609477bc31aa880938",
      "c12c857f159443f1b2a661fcd7afa002",
      "989933f9c84a47d4b64d5b5441a1f492",
      "2024092105904b418c984aae9f4118bf",
      "4cc5655f9bdb42bca5d80e2849e8cd2b",
      "fd56d3ae17774e5496a7fdcbcb57b874",
      "b5516712d5304670a05ec871eb5896a4",
      "9910be9c8b7b4188936721e958ca15c5",
      "50859aa086814457bcab249b35d486a8",
      "4f0a4e1b4929448a8b0a25b202271a40",
      "ac93c61a19c0474994803853194d2aa8",
      "ee12049f5a9c4505b9769a4ff9c36477",
      "18e134c7af5d45baa952ccf06f96f3d8",
      "21bf2e03eac8419fa693628ab2cef02d",
      "0f14c359d92748268810099e6cdd1fc3",
      "e99b3d05437f4cdf9e1700e3cf466b34",
      "4f1d5a79d7ec4e42add7775fa925b187",
      "e89d668a4fb541ec8d75d171bf899869",
      "430a9d1768614e0596960d2a3d15d69e",
      "909ae03e117345f7a4b53f3045e090b7",
      "06285d669e92494192637cb3ee5a40f4",
      "209ee3e0949b446b8c58c57989065c5a",
      "672e978f9b524c5784553abd8cc91507",
      "17ae300ebf634778862bc211cb432eef",
      "5a072e1f73624ea5aa35e7e18af17f50",
      "1ec35f8bfadb40968f777ab7bbb55184",
      "274875a4aa6047c9903ae3065a5d85c2",
      "a51f1ae4e3bd4563be3eb7c04dec7a60",
      "c7586ac9b41c4e75b02a6c076a458686",
      "8a0c04349bae44f4a7130463ded826d1",
      "9f11959bab964aad822250b6e6853cb8",
      "9b0c918326174bc4b80585a52ac33e32",
      "e38ea829111b4065bad8ad4a4927bc39"
     ]
    },
    "id": "qe9vOPP6TD5-",
    "outputId": "d30dde8d-148a-4d7c-d57d-05ebeb164a73",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load bertModel, bertTokenizer and freeze all layers\n",
    "bertModel = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "bertModel.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "oBwXHsyyTMLh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset generator (for input to tf.data.Dataset.from_generator())\n",
    "\n",
    "class dataset:\n",
    "\n",
    "    def __init__(self,text,labels,attention_score,max_length, tokenizer,projection_dim, val = False):\n",
    "\n",
    "        self.text =   text\n",
    "        self.labels = labels\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "        self.flag = val\n",
    "        self.projection_dim = projection_dim\n",
    "        self.attention_score=attention_score\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return  self.text.shape[0]\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        sentence = self.text[index]\n",
    "        category = self.labels[index]\n",
    "        attention_score=self.attention_score[index]\n",
    "\n",
    "        return sentence, category, attention_score\n",
    "\n",
    "\n",
    "  # shuffle the dataset after each epoch\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        random_idx = random.sample(list(range(self.__len__())), k = self.__len__())\n",
    "        self.text   = self.text[random_idx]\n",
    "        self.labels = self.labels[random_idx]\n",
    "        self.attention_score=self.attention_score[random_idx]\n",
    "        \n",
    "\n",
    "    def __call__(self):\n",
    "\n",
    "        for i in range(self.__len__()):\n",
    "            sentence, label ,attention_score= self.__getitem__(i)\n",
    "            # attention_score_padded = np.pad(attention_score, (0, self.max_length - len(attention_score)), 'constant')\n",
    "            attention_score_padded = np.pad(attention_score[:self.max_length], (0, max(0, self.max_length - len(attention_score))), 'constant')\n",
    "\n",
    "            encodings = self.tokenizer(sentence,\n",
    "                                     max_length = self.max_length,\n",
    "                                     padding = \"max_length\",\n",
    "                                     truncation = True)\n",
    "            \n",
    "    \n",
    "\n",
    "            input_ids  = np.array(encodings[\"input_ids\"])\n",
    "            masks      = np.array(encodings[\"attention_mask\"])\n",
    "            ttids      = np.array(encodings[\"token_type_ids\"])\n",
    "            \n",
    "            \n",
    "\n",
    "            embedding_index = np.array([i for i in range(self.projection_dim)])\n",
    "            embedding_index = np.ravel(embedding_index)\n",
    "\n",
    "            embedding_index = np.tile(embedding_index, (input_ids[0:1].shape[0],))\n",
    "\n",
    "            yield {\"input_ids\": input_ids, \"attention_masks\": masks,\"space\": embedding_index,\"attention_score\":attention_score_padded},label\n",
    "\n",
    "\n",
    "            # randomize the dataset on epoch end, only in case of training dataset\n",
    "            if i == self.__len__() -1 and self.flag is False:\n",
    "                self.on_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGGXmXltToJP"
   },
   "source": [
    "# Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "gTFK9EDvT6mW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## AUXILLIARY FUNCTIONS\n",
    "def dataprep(PROJECTION_DIM):\n",
    "    train_gen = dataset(train_df[\"tweet\"].values,train_df[\"class\"].values,train_df[\"softmax_numbers\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer,projection_dim=PROJECTION_DIM)\n",
    "    val_gen   = dataset(val_df[\"tweet\"].values,val_df[\"class\"].values,val_df[\"softmax_numbers\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer, projection_dim=PROJECTION_DIM, val = True)\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_generator(train_gen,\n",
    "                                                output_signature =\n",
    "                                               ( {\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\n",
    "                                                  \"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32),\"attention_score\":tf.TensorSpec(shape=(MAX_LENGTH,),dtype=tf.float32)},\n",
    "                                                tf.TensorSpec(shape = (), dtype = (tf.float32)))).repeat().batch(batch_size = BATCH_SIZE) # shuffling is already implemented in dataset class\n",
    "\n",
    "    val_ds = tf.data.Dataset.from_generator(val_gen,\n",
    "                                                output_signature =\n",
    "                                               ( {\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\n",
    "                                                  \"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32),\"attention_score\":tf.TensorSpec(shape=(MAX_LENGTH,),dtype=tf.float32)},\n",
    "                                                tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)\n",
    "\n",
    "    return train_ds,val_ds\n",
    "# train_ds,val_ds=dataprep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i in train_ds.take(1):\n",
    "#     temp=i\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "crv2VhKhUBiQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NA\n",
    "def return_embedding_index(x_train,count):\n",
    "\n",
    "    embedding_index=np.array([i for i in range(count)])\n",
    "\n",
    "    embeding_index=np.ravel(embedding_index) # flattens the array\n",
    "\n",
    "    rank = len(x_train.shape)\n",
    "    if rank < 3:\n",
    "        embedding_index = np.tile(embedding_index,(x_train[0:1].shape[0],1,))\n",
    "    else:\n",
    "        embedding_index = np.tile(embedding_index,(x_train.shape[0],1,))\n",
    "\n",
    "    return embedding_index\n",
    "\n",
    "\n",
    "# cosine similarity b/w two vectors\n",
    "def cosine_similarity_projected(vects):\n",
    "\n",
    "    x,w=vects\n",
    "\n",
    "    dp = tf.matmul(x, w)\n",
    "\n",
    "\n",
    "    x_mag = tf.norm(x, axis=2, keepdims = True)\n",
    "\n",
    "    w_mag = tf.norm(w,axis = 1, keepdims = True)\n",
    "\n",
    "    denominator = dp / x_mag\n",
    "    cosine = denominator / w_mag\n",
    "\n",
    "    return cosine\n",
    "\n",
    "# NA\n",
    "def compare_cosine(vector):\n",
    "\n",
    "    violent,normal=vector\n",
    "\n",
    "    peace=tf.math.reduce_mean(peace, axis=1)\n",
    "    violent=tf.math.reduce_mean(violent, axis=1)\n",
    "    normal=tf.math.reduce_mean(normal, axis=1)\n",
    "    out=tf.concat([peace,violent,normal],axis=-1)\n",
    "    print(\"COMPARE-COSINE\")\n",
    "    print('out.shape')\n",
    "    print(out.shape)\n",
    "\n",
    "\n",
    "    return out\n",
    "\n",
    "# NA\n",
    "# takes mean embeddings\n",
    "class remove_pads(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "\n",
    "        super(remove_pads,self).__init__(**kwargs)\n",
    "        self.mask_generator = layers.Embedding(input_dim = 35000,output_dim = 32, mask_zero=True)\n",
    "\n",
    "\n",
    "\n",
    "    def call(self,listInputs):\n",
    "\n",
    "        inputs = listInputs[0]\n",
    "        input_ids = listInputs[1]\n",
    "        masks = self.mask_generator.compute_mask(input_ids)\n",
    "        masks = tf.cast(masks,tf.float32)\n",
    "        masks = tf.expand_dims(masks,axis=-1)\n",
    "        temp = tf.unstack(masks,axis=1)\n",
    "        del temp[0]\n",
    "        temp.insert(0,tf.zeros_like(temp[0]))\n",
    "        masks = tf.stack(temp,axis=1)\n",
    "        length = tf.math.reduce_sum(masks,axis = 1, keepdims=True)     # (None,1,1)\n",
    "        # mask the embeddings corresponding to zero input id ==0\n",
    "        masked_embeddings = inputs * masks    # (None,64,300) * (None,64,1) = (None,64,300)\n",
    "        # take SUM, (not mean)\n",
    "        masked_embeddings = tf.math.reduce_sum(masked_embeddings, axis = 1, keepdims=True)\n",
    "        # now just divide each by the length to get mean of non zero embeddings\n",
    "        masked_embeddings = masked_embeddings / length\n",
    "\n",
    "        return masked_embeddings\n",
    "\n",
    "\n",
    "\n",
    "class remove_padsV2(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self,**kwargs):\n",
    "\n",
    "        super(remove_padsV2,self).__init__(**kwargs)\n",
    "        self.mask_generator = layers.Embedding(input_dim = 35000,output_dim = 32, mask_zero=True)  # bert has vocabulary of 30522 words\n",
    "\n",
    "\n",
    "\n",
    "    def call(self,listInputs):\n",
    "\n",
    "        inputs = listInputs[0]                   # (None,MAX_LENGTH,PROJECTION_DIM)\n",
    "        input_ids = listInputs[1]                # (None,MAX_LENGTH)\n",
    "\n",
    "        # convert token ids 101 and 102 to 0\n",
    "        filteredInputIds = tf.where(tf.equal(input_ids,101) | tf.equal(input_ids,102),0,input_ids)\n",
    "        # get masks for input ids\n",
    "        masks = self.mask_generator.compute_mask(filteredInputIds)\n",
    "        masks = tf.cast(masks,tf.float32)\n",
    "        masks = tf.expand_dims(masks,axis=-1)    # (None,MAX_LENGTH,1)\n",
    "\n",
    "        masked_embeddings = inputs * masks\n",
    "\n",
    "        return masked_embeddings\n",
    "\n",
    "\n",
    "\n",
    "# mean embeddings\n",
    "def merge_function(vects):\n",
    "\n",
    "    negative,normal = [vects[0], vects[1]]    # (None,MAX_LENGTH,PROJECTION_DIM)\n",
    "\n",
    "\n",
    "    # of these 128 vectors, those corresponding to tokens [cls, pad, sep] are 0\n",
    "    # we sum them up and then divide with number of non-zeros to get average cosine similarities\n",
    "    # positiveLength = tf.math.count_nonzero(tf.math.reduce_sum(positive, axis=2,keepdims=True), axis=1, keepdims=True,dtype = tf.float32)   # (None,1,1)\n",
    "    negativeLength = tf.math.count_nonzero(tf.math.reduce_sum(negative, axis=2,keepdims=True), axis=1, keepdims=True,dtype = tf.float32)\n",
    "    normalLength = tf.math.count_nonzero(tf.math.reduce_sum(normal, axis=2,keepdims=True), axis=1, keepdims=True,dtype = tf.float32)\n",
    "\n",
    "\n",
    "    # now obtain average of cosine similarities\n",
    "    # positive = tf.math.reduce_sum(positive,axis=1, keepdims=True)    # (None,1,PROJECTION_DIM)\n",
    "    # positiveAverage = tf.divide(positive, positiveLength)\n",
    "\n",
    "    negative = tf.math.reduce_sum(negative,axis=1, keepdims=True)    # (None,1,PROJECTION_DIM)\n",
    "    negativeAverage = tf.divide(negative, negativeLength)\n",
    "\n",
    "    normal = tf.math.reduce_sum(normal,axis=1, keepdims=True)    # (None,1,PROJECTION_DIM)\n",
    "    normalAverage = tf.divide(normal, negativeLength)\n",
    "\n",
    "\n",
    "\n",
    "    # input_shape = (None,1,Projection_DIM)\n",
    "    res = tf.concat([positiveAverage,negativeAverage,normalAverage], axis = -1)    # (None,1,PROJECTION_DIM)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "# max embeddings\n",
    "def merge_functionV2(vects):\n",
    "\n",
    "    negative,normal = vects[0], vects[1], \n",
    "    # of these 128 vectors, those corresponding to tokens [cls, pad, sep] are 0\n",
    "\n",
    "\n",
    "    # TAKE MAXIMUM COSINE SIMILARITY OF ALL THE TOKENS OF A SENTENCE WRT EACH PROJECTION DIM\n",
    "    # positiveMax = tf.reduce_max(positive, axis=1, keepdims=True)     # (None, 1, PROJECTION_DIM)\n",
    "    negativeMax = tf.reduce_max(negative, axis=1, keepdims=True)\n",
    "    normalMax = tf.reduce_max(normal, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "    res = tf.concat([negativeMax,normalMax], axis = -1)            # (None,1,  2 * PROJECTION_DIM)\n",
    "\n",
    "    return res\n",
    "\n",
    "# increase stdDevLoss in projection dimension\n",
    "def StdDevLoss(x):                                                              # (None,MAX_LEN,PROJECTION_DIM)\n",
    "\n",
    "    stdDev = tf.math.reduce_std(x,axis=2)                                         # (None,MAX_LEN)\n",
    "    stdDevLoss = tf.math.reduce_mean(stdDev)\n",
    "\n",
    "    return stdDevLoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xVIgFoIztcq"
   },
   "source": [
    "Loading Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "emoMqT3RUGKH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "DEBUG = \"DEBUG\"\n",
    "# PROJECTION_DIM=10\n",
    "# for input we have\n",
    "# 1. input ids\n",
    "# 2. attention_masks\n",
    "# 3. embedding_index (PROJECTION_DIM)\n",
    "# 4. label\n",
    "\n",
    "def spock_model(MAX_LENGTH,PROJECTION_DIM,lambda_value):\n",
    "    DEBUG = \"DEBUG\"\n",
    "    VECTOR_DIM=768\n",
    "    # first two will go to bert as input\n",
    "    ids = layers.Input(shape = (MAX_LENGTH,), dtype = tf.int32, name = \"input_ids\")\n",
    "    mks = layers.Input(shape = (MAX_LENGTH,), dtype = tf.int32, name = \"attention_masks\")\n",
    "    projection_space = layers.Input(name = \"space\", shape = (PROJECTION_DIM,))\n",
    "    attention_score=layers.Input(name = \"attention_score\", shape = (MAX_LENGTH,), dtype = tf.float32)\n",
    "\n",
    "\n",
    "    input_sentence = bertModel(ids, attention_mask = mks)[0]                        # layers freezed, last_hidden_state_output\n",
    "\n",
    "\n",
    "\n",
    "    offensive_embedding_layer =  layers.Embedding(name = \"offensive_embedding\",\n",
    "                                       input_dim=PROJECTION_DIM,\n",
    "                                       output_dim=VECTOR_DIM,\n",
    "                                       embeddings_initializer=tf.random_uniform_initializer(minval=-1., maxval=1.),\n",
    "                                       input_length = PROJECTION_DIM ,\n",
    "                                       # weights=hate_weights,\n",
    "                                       trainable=True,\n",
    "                                       mask_zero=True)\n",
    "\n",
    "\n",
    "    normal_embedding_layer =  layers.Embedding(name = \"normal_embedding\",\n",
    "                                       input_dim=PROJECTION_DIM,\n",
    "                                       output_dim=VECTOR_DIM,\n",
    "                                       embeddings_initializer=tf.random_uniform_initializer(minval=-1., maxval=1.),\n",
    "                                       input_length = PROJECTION_DIM ,\n",
    "                                       # weights=hate_weights,\n",
    "                                       trainable=True,\n",
    "                                       mask_zero=True)\n",
    "\n",
    "\n",
    "    # embeddings for projection space\n",
    "    # hate_embedding_np = hate_embedding_layer(projection_space)              # (None,PROJECTION_DIM,VECTOR_DIM)\n",
    "    offensive_embedding_np = offensive_embedding_layer(projection_space)     # (None,PROJECTION_DIM,VECTOR_DIM)\n",
    "    normal_embedding_np = normal_embedding_layer(projection_space)     # (None,PROJECTION_DIM,VECTOR_DIM)\n",
    "\n",
    "    #Permute\n",
    "    # hate_embedding= layers.Permute((2, 1), input_shape=(PROJECTION_DIM, VECTOR_DIM))(hate_embedding_np)\n",
    "    offensive_embedding= layers.Permute((2, 1), input_shape=(PROJECTION_DIM, VECTOR_DIM))(offensive_embedding_np)\n",
    "    normal_embedding= layers.Permute((2, 1), input_shape=(PROJECTION_DIM, VECTOR_DIM))(normal_embedding_np)\n",
    "\n",
    "\n",
    "\n",
    "    # neg_projection_space\n",
    "    offensive_cosine = layers.Lambda(function=cosine_similarity_projected,\n",
    "                             name='cosine_offensive')([input_sentence, offensive_embedding])\n",
    "\n",
    "    # normal_projection_space\n",
    "    normal_cosine = layers.Lambda(function=cosine_similarity_projected,\n",
    "                             name='cosine_normal')([input_sentence, normal_embedding])\n",
    "\n",
    "\n",
    "    # remove paddings from cosines from both layers\n",
    "    # hate_cosine_nopads = remove_padsV2(name=\"remove_cls_pad_hate\")([hate_cosine, ids])   # (None,MAX_LENGTH,PROJECTION_DIM)\n",
    "    offensive_cosine_nopads = remove_padsV2(name=\"remove_cls_pad_offensive\")([offensive_cosine, ids])\n",
    "    normal_cosine_nopads = remove_padsV2(name=\"remove_cls_pad_normal\")([normal_cosine, ids])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # merge (v1: mean, v2: max)\n",
    "    merged = layers.Lambda(function=merge_functionV2,\n",
    "                    name='TakeMaxCosineAndCompare')([offensive_cosine_nopads,normal_cosine_nopads])  # (None,1,1002)    # !these values are not really identical beacause both embedding layers had different random weights\n",
    "\n",
    "    merged = layers.Flatten(data_format = \"channels_first\")(merged)\n",
    "\n",
    "\n",
    "    # CLASSIFICATION HEAD\n",
    "\n",
    "    hidden = layers.Dense(612, activation='relu', name = \"hidden-1\", kernel_constraint=MaxNorm(3),\n",
    "                   kernel_initializer = \"he_normal\")(merged)\n",
    "\n",
    "    hidden = layers.Dense(256, activation='relu', name = \"hidden-1\", kernel_constraint=MaxNorm(3),\n",
    "                   kernel_initializer = \"he_normal\")(merged)\n",
    "\n",
    "    # hidden = layers.Dropout(0.6, name=\"drop-1\")(hidden)\n",
    "    hidden = layers.Dense(64, activation='relu', name = \"hidden-2\", kernel_constraint=MaxNorm(3),\n",
    "                   kernel_initializer = \"he_normal\")(hidden)\n",
    "    # hidden = layers.Dropout(0.3, name=\"drop-2\")(hidden)\n",
    "    hidden_tt = layers.Dense(30, activation='relu', name = \"hidden-3\", kernel_constraint=MaxNorm(3),\n",
    "                   kernel_initializer= \"he_normal\")(hidden)\n",
    "    # hidden = layers.Dropout(0.25, name=\"drop-3\")(hidden)\n",
    "\n",
    "\n",
    "    predictions = layers.Dense(1, activation= \"sigmoid\" , name='classification_layer')(hidden_tt)\n",
    "\n",
    "    model = Model(inputs=[ids, mks, projection_space,attention_score],outputs= predictions)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    offensive_normal_loss = 1.0/(1.01 + tf.keras.losses.CosineSimilarity(name='offensive_normal_loss')\n",
    "                                 (tf.math.reduce_mean(offensive_cosine, axis=1), tf.math.reduce_mean(normal_cosine, axis=1))) \n",
    "    \n",
    "    model.add_loss(offensive_normal_loss)\n",
    "    model.add_metric(offensive_normal_loss, name='Interspace')\n",
    "\n",
    "    # #posStdDevLoss = StdDevLoss(hate_cosine)\n",
    "    ToxicIntra_Loss = 1.0/(tf.math.reduce_std(offensive_cosine)+ 0.001)\n",
    "    Non_toxicIntra_Loss = 1.0/(tf.math.reduce_std(normal_cosine)+ 0.001)\n",
    "    \n",
    "    model.add_loss(ToxicIntra_Loss)\n",
    "    model.add_loss(Non_toxicIntra_Loss)\n",
    "    \n",
    "    model.add_metric(ToxicIntra_Loss, name='ToxicIntra_Loss')\n",
    "    model.add_metric(Non_toxicIntra_Loss, name='Non_toxicIntra_Loss')\n",
    "\n",
    "\n",
    "    \n",
    "    # cross entropy loss\n",
    "    '''If your 𝑌𝑖\n",
    "    # 's are one-hot encoded, use categorical_crossentropy. Examples (for a 3-class classification): [1,0,0] , [0,1,0], [0,0,1]\n",
    "    # But if your 𝑌𝑖\n",
    "    # 's are integers, use sparse_categorical_crossentropy. \"Examples for above 3-class classification problem: [1] , [2], [3]\n",
    "    '''\n",
    "\n",
    "    # crossEntropLoss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "#     \n",
    "    crossEntropLoss1 = tf.keras.losses.BinaryCrossentropy(from_logits=False,name='Attention_Loss_binary_crossentropy')\n",
    "    \n",
    "\n",
    "    \n",
    "    #adding attention score to get the loss using binary corss entropy between annonatators attention score\n",
    "    # and attention score assigned by final layer\n",
    "    bce_loss1=crossEntropLoss1(attention_score,hidden_tt)\n",
    "    \n",
    "    model.add_loss(lambda_value*bce_loss1)\n",
    "    model.add_metric(bce_loss1, name='Attention_Loss')\n",
    "    \n",
    "\n",
    "    crossEntropLoss2 = tf.keras.losses.BinaryCrossentropy(from_logits=False, name='binary_crossentropy')\n",
    "\n",
    "    # optimize can compile\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-3, clipnorm = 1.0)\n",
    "    model.compile(loss = crossEntropLoss2, optimizer = optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Training and Saving "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-46-a904cf409b29&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-45-e857ccf52ade&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">139</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">spock_model</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">losses.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">141</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 138 │   │   </span>call_fn = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.call                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 139 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 140 │   │   </span>call_fn = tf.__internal__.autograph.tf_convert(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.call, tf.__internal__.autogr  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 141 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>losses = call_fn(y_true, y_pred)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 142 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> losses_utils.compute_weighted_loss(                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 143 │   │     </span>losses, sample_weight, reduction=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_reduction())                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 144 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">losses.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">245</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">call</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 242 │     </span>y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 243 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 244 │   </span>ag_fn = tf.__internal__.autograph.tf_convert(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fn, tf.__internal__.autograph.cont  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 245 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> ag_fn(y_true, y_pred, **<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fn_kwargs)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 246   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 247   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_config</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 248 │   </span>config = {}                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/lib/python3/dist-packages/tensorflow/python/util/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">traceback_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">153</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">error_handler</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">150 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fn(*args, **kwargs)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">151 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">152 │     </span>filtered_tb = _process_traceback_frames(e.__traceback__)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>153 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> e.with_traceback(filtered_tb) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">None</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">finally</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">del</span> filtered_tb                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1473</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">handle</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1470 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">any</span>(                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1471 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(x, keras_tensor.KerasTensor)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1472 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> x <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> tf.nest.flatten([args, kwargs])):                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1473 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> TFOpLambda(op)(*args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1474 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1475 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.NOT_SUPPORTED                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1476 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/engine/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base_layer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">976</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 973 │   # &gt;&gt; outputs = MyLayer()(inputs)  # Functional construction mode.</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 974 │   # &gt;&gt; model = tf.keras.Model(inputs, outputs)</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 975 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _in_functional_construction_mode(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs, args, kwargs, input_list):          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 976 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._functional_construction_call(inputs, args, kwargs,                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 977 │   │   │   │   │   │   │   │   │   │   │   │   </span>input_list)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 978 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 979 │   # Maintains info about the `Layer.call` stack.</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/engine/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base_layer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1114</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_functional_construction_call</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1111 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> call_context.enter(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1112 │   │   </span>layer=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs=inputs, build_graph=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, training=training_value):            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1113 │     # Check input assumptions set after layer building, e.g. input shape.</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1114 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._keras_tensor_symbolic_call(                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1115 │   │     </span>inputs, input_masks, args, kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1116 │     </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1117 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> outputs <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/engine/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base_layer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">848</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_keras_tensor_symbolic_call</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 845 │     </span>output_signature = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_output_signature(input_signature)                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 846 │     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> tf.nest.map_structure(keras_tensor.KerasTensor, output_signature)            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 847 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 848 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._infer_output_signature(inputs, args, kwargs, input_masks)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 849   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 850   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_infer_output_signature</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, inputs, args, kwargs, input_masks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 851 </span><span style=\"color: #bfbfbf; text-decoration-color: #bfbfbf\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"TODO(kaftan): Docstring.\"\"\"</span>                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/engine/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base_layer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">888</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_infer_output_signature</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 885 │   │     # TODO(kaftan): do we maybe_build here, or have we already done it?</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 886 │   │     </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_build(inputs)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 887 │   │     </span>inputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_cast_inputs(inputs)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 888 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │     </span>outputs = call_fn(inputs, *args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 889 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 890 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._handle_activity_regularization(inputs, outputs)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 891 │     </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._set_mask_metadata(inputs, outputs, input_masks,                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1350</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_wrapper</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1347 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1348 │   # Decorate the function to produce this layer's call method</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1349 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_wrapper</span>(*args, **kwargs):                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1350 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call_wrapper(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1351 │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.call = tf.__internal__.decorator.make_decorator(function, _call_wrapper)         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1352 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1353 │   # Do not individually trace op layers in the SavedModel.</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/layers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">core.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1382</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_wrapper</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1379 │     # `name` passed (which is susceptible to producing</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1380 │     # multiple ops w/ the same name when the layer is reused)</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1381 │     </span>kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">'name'</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1382 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>result = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.function(*args, **kwargs)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1383 │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._check_variables(created_variables, tape.watched_variables())                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1384 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> result                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1385 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">losses.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1809</span> in                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_crossentropy</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1806 │   │   │   │   │   │   │   │    </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">lambda</span>: y_true)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1807   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1808   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> backend.mean(                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1809 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│     </span>backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1810 │     </span>axis=axis)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1811 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1812 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">backend.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5015</span> in                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">binary_crossentropy</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5012   </span>output = tf.clip_by_value(output, epsilon_, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.</span> - epsilon_)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5013   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5014   # Compute cross entropy from probabilities.</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>5015 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">  </span>bce = target * tf.math.log(output + epsilon())                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5016   </span>bce += (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> - target) * tf.math.log(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> - output + epsilon())                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5017   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> -bce                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5018 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Dimensions must be equal, but are <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span> and <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span> for <span style=\"color: #008000; text-decoration-color: #008000\">'{{node tf.keras.metrics.binary_crossentropy/mul}} = </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Mul[T=DT_FLOAT](Placeholder, tf.keras.metrics.binary_crossentropy/Log)'</span> with input shapes: <span style=\"font-weight: bold\">[</span>?,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span>?,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">60</span><span style=\"font-weight: bold\">]</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-46-a904cf409b29>\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-45-e857ccf52ade>\u001b[0m:\u001b[94m139\u001b[0m in \u001b[92mspock_model\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/\u001b[0m\u001b[1;33mlosses.py\u001b[0m:\u001b[94m141\u001b[0m in \u001b[92m__call__\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 138 \u001b[0m\u001b[2m│   │   \u001b[0mcall_fn = \u001b[96mself\u001b[0m.call                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 139 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94melse\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 140 \u001b[0m\u001b[2m│   │   \u001b[0mcall_fn = tf.__internal__.autograph.tf_convert(\u001b[96mself\u001b[0m.call, tf.__internal__.autogr  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 141 \u001b[2m│     \u001b[0mlosses = call_fn(y_true, y_pred)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 142 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m losses_utils.compute_weighted_loss(                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 143 \u001b[0m\u001b[2m│   │     \u001b[0mlosses, sample_weight, reduction=\u001b[96mself\u001b[0m._get_reduction())                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 144 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/\u001b[0m\u001b[1;33mlosses.py\u001b[0m:\u001b[94m245\u001b[0m in \u001b[92mcall\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 242 \u001b[0m\u001b[2m│     \u001b[0my_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 243 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 244 \u001b[0m\u001b[2m│   \u001b[0mag_fn = tf.__internal__.autograph.tf_convert(\u001b[96mself\u001b[0m.fn, tf.__internal__.autograph.cont  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 245 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m ag_fn(y_true, y_pred, **\u001b[96mself\u001b[0m._fn_kwargs)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 246 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 247 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mget_config\u001b[0m(\u001b[96mself\u001b[0m):                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 248 \u001b[0m\u001b[2m│   \u001b[0mconfig = {}                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/lib/python3/dist-packages/tensorflow/python/util/\u001b[0m\u001b[1;33mtraceback_utils.py\u001b[0m:\u001b[94m153\u001b[0m in \u001b[92merror_handler\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m150 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m fn(*args, **kwargs)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m151 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m \u001b[94mas\u001b[0m e:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│     \u001b[0mfiltered_tb = _process_traceback_frames(e.__traceback__)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m153 \u001b[2m│     \u001b[0m\u001b[94mraise\u001b[0m e.with_traceback(filtered_tb) \u001b[94mfrom\u001b[0m \u001b[96mNone\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfinally\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mdel\u001b[0m filtered_tb                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/layers/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m1473\u001b[0m in \u001b[92mhandle\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1470 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[96many\u001b[0m(                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1471 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96misinstance\u001b[0m(x, keras_tensor.KerasTensor)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1472 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m x \u001b[95min\u001b[0m tf.nest.flatten([args, kwargs])):                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1473 \u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m TFOpLambda(op)(*args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1474 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1475 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.NOT_SUPPORTED                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1476 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/engine/\u001b[0m\u001b[1;33mbase_layer.py\u001b[0m:\u001b[94m976\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m__call__\u001b[0m                                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 973 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 974 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 975 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m _in_functional_construction_mode(\u001b[96mself\u001b[0m, inputs, args, kwargs, input_list):          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 976 \u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._functional_construction_call(inputs, args, kwargs,                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 977 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0minput_list)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 978 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 979 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Maintains info about the `Layer.call` stack.\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/engine/\u001b[0m\u001b[1;33mbase_layer.py\u001b[0m:\u001b[94m1114\u001b[0m in       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_functional_construction_call\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1111 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m call_context.enter(                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1112 \u001b[0m\u001b[2m│   │   \u001b[0mlayer=\u001b[96mself\u001b[0m, inputs=inputs, build_graph=\u001b[94mTrue\u001b[0m, training=training_value):            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1113 \u001b[0m\u001b[2m│     \u001b[0m\u001b[2m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1114 \u001b[2m│     \u001b[0moutputs = \u001b[96mself\u001b[0m._keras_tensor_symbolic_call(                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1115 \u001b[0m\u001b[2m│   │     \u001b[0minputs, input_masks, args, kwargs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1116 \u001b[0m\u001b[2m│     \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1117 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mif\u001b[0m outputs \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/engine/\u001b[0m\u001b[1;33mbase_layer.py\u001b[0m:\u001b[94m848\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_keras_tensor_symbolic_call\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 845 \u001b[0m\u001b[2m│     \u001b[0moutput_signature = \u001b[96mself\u001b[0m.compute_output_signature(input_signature)                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 846 \u001b[0m\u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m tf.nest.map_structure(keras_tensor.KerasTensor, output_signature)            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 847 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 848 \u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._infer_output_signature(inputs, args, kwargs, input_masks)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 849 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 850 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_infer_output_signature\u001b[0m(\u001b[96mself\u001b[0m, inputs, args, kwargs, input_masks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 851 \u001b[0m\u001b[2;90m│   \u001b[0m\u001b[33m\"\"\"TODO(kaftan): Docstring.\"\"\"\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/engine/\u001b[0m\u001b[1;33mbase_layer.py\u001b[0m:\u001b[94m888\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_infer_output_signature\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 885 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[2m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 886 \u001b[0m\u001b[2m│   │     \u001b[0m\u001b[96mself\u001b[0m._maybe_build(inputs)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 887 \u001b[0m\u001b[2m│   │     \u001b[0minputs = \u001b[96mself\u001b[0m._maybe_cast_inputs(inputs)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 888 \u001b[2m│   │     \u001b[0moutputs = call_fn(inputs, *args, **kwargs)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 889 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 890 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._handle_activity_regularization(inputs, outputs)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 891 \u001b[0m\u001b[2m│     \u001b[0m\u001b[96mself\u001b[0m._set_mask_metadata(inputs, outputs, input_masks,                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/layers/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m1350\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_wrapper\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1347 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1348 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Decorate the function to produce this layer's call method\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1349 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_call_wrapper\u001b[0m(*args, **kwargs):                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1350 \u001b[2m│     \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._call_wrapper(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1351 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mself\u001b[0m.call = tf.__internal__.decorator.make_decorator(function, _call_wrapper)         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1352 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1353 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Do not individually trace op layers in the SavedModel.\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/layers/\u001b[0m\u001b[1;33mcore.py\u001b[0m:\u001b[94m1382\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_call_wrapper\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1379 \u001b[0m\u001b[2m│     \u001b[0m\u001b[2m# `name` passed (which is susceptible to producing\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1380 \u001b[0m\u001b[2m│     \u001b[0m\u001b[2m# multiple ops w/ the same name when the layer is reused)\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1381 \u001b[0m\u001b[2m│     \u001b[0mkwargs.pop(\u001b[33m'\u001b[0m\u001b[33mname\u001b[0m\u001b[33m'\u001b[0m, \u001b[94mNone\u001b[0m)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1382 \u001b[2m│     \u001b[0mresult = \u001b[96mself\u001b[0m.function(*args, **kwargs)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1383 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mself\u001b[0m._check_variables(created_variables, tape.watched_variables())                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1384 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m result                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1385 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/\u001b[0m\u001b[1;33mlosses.py\u001b[0m:\u001b[94m1809\u001b[0m in                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mbinary_crossentropy\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1806 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │    \u001b[0m\u001b[94mlambda\u001b[0m: y_true)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1807 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1808 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m backend.mean(                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1809 \u001b[2m│     \u001b[0mbackend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1810 \u001b[0m\u001b[2m│     \u001b[0maxis=axis)                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1811 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1812 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/naseem_fordham/.local/lib/python3.8/site-packages/keras/\u001b[0m\u001b[1;33mbackend.py\u001b[0m:\u001b[94m5015\u001b[0m in                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mbinary_crossentropy\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5012 \u001b[0m\u001b[2m  \u001b[0moutput = tf.clip_by_value(output, epsilon_, \u001b[94m1.\u001b[0m - epsilon_)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5013 \u001b[0m\u001b[2m  \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5014 \u001b[0m\u001b[2m  \u001b[0m\u001b[2m# Compute cross entropy from probabilities.\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m5015 \u001b[2m  \u001b[0mbce = target * tf.math.log(output + epsilon())                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5016 \u001b[0m\u001b[2m  \u001b[0mbce += (\u001b[94m1\u001b[0m - target) * tf.math.log(\u001b[94m1\u001b[0m - output + epsilon())                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5017 \u001b[0m\u001b[2m  \u001b[0m\u001b[94mreturn\u001b[0m -bce                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5018 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mDimensions must be equal, but are \u001b[1;36m30\u001b[0m and \u001b[1;36m60\u001b[0m for \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32mnode tf.keras.metrics.binary_crossentropy/mul\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = \u001b[0m\n",
       "\u001b[32mMul\u001b[0m\u001b[32m[\u001b[0m\u001b[32mT\u001b[0m\u001b[32m=\u001b[0m\u001b[32mDT_FLOAT\u001b[0m\u001b[32m]\u001b[0m\u001b[32m(\u001b[0m\u001b[32mPlaceholder, tf.keras.metrics.binary_crossentropy/Log\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m with input shapes: \u001b[1m[\u001b[0m?,\u001b[1;36m30\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m?,\u001b[1;36m60\u001b[0m\u001b[1m]\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 16\n",
    "PROJECTION_DIM =30\n",
    "VECTOR_DIM = 768\n",
    "\n",
    "spock_model1= spock_model(MAX_LENGTH, PROJECTION_DIM,2)\n",
    "\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(spock_model1, to_file='spock_model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "# Plot the model graph and display it in the notebook\n",
    "# tf.keras.utils.plot_model(spock_model1, show_shapes=True, show_layer_names=True, to_file='model_plot.png')\n",
    "# Image('model_plot.png')\n",
    "# spock_model1.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiazliz the tensorboard to visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "#1st laod the teansorbaord before tarining\n",
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAX_LENGTH = 30\n",
    "# BATCH_SIZE = 16\n",
    "# PROJECTION_DIM =30\n",
    "# VECTOR_DIM = 768\n",
    "# \n",
    "# spock_model1= spock_model(MAX_LENGTH, PROJECTION_DIM)\n",
    "# spock_model1.summary()\\\n",
    "# tf.keras.backend.clear_session()\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ps aux | grep tensorboard\n",
    "# !kill 146651\n",
    "!pkill -f tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tf.profiler.experimental.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "id": "OJHKxhG4Uphm",
    "outputId": "8e989294-bc36-4224-f212-269241763980",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "503/503 [==============================] - 34s 54ms/step - loss: 23.9776 - accuracy: 0.5630 - Interspace: 0.9002 - ToxicIntra_Loss: 11.0111 - Non_toxicIntra_Loss: 11.0686 - Attention_Loss: 0.1555 - val_loss: 14.1245 - val_accuracy: 0.5665 - val_Interspace: 0.8359 - val_ToxicIntra_Loss: 6.1553 - val_Non_toxicIntra_Loss: 6.1560 - val_Attention_Loss: 0.1464\n",
      "Epoch 2/5\n",
      "503/503 [==============================] - 24s 48ms/step - loss: 12.2243 - accuracy: 0.5664 - Interspace: 0.8155 - ToxicIntra_Loss: 5.2162 - Non_toxicIntra_Loss: 5.2147 - Attention_Loss: 0.1468 - val_loss: 10.3727 - val_accuracy: 0.5665 - val_Interspace: 0.7999 - val_ToxicIntra_Loss: 4.3037 - val_Non_toxicIntra_Loss: 4.2943 - val_Attention_Loss: 0.1455\n",
      "Epoch 3/5\n",
      "503/503 [==============================] - 24s 48ms/step - loss: 9.7231 - accuracy: 0.5664 - Interspace: 0.7895 - ToxicIntra_Loss: 3.9807 - Non_toxicIntra_Loss: 3.9767 - Attention_Loss: 0.1461 - val_loss: 8.7699 - val_accuracy: 0.5665 - val_Interspace: 0.7811 - val_ToxicIntra_Loss: 3.5099 - val_Non_toxicIntra_Loss: 3.5055 - val_Attention_Loss: 0.1451\n",
      "Epoch 4/5\n",
      "503/503 [==============================] - 24s 48ms/step - loss: 8.4792 - accuracy: 0.5670 - Interspace: 0.7748 - ToxicIntra_Loss: 3.3661 - Non_toxicIntra_Loss: 3.3671 - Attention_Loss: 0.1441 - val_loss: 7.8554 - val_accuracy: 0.5665 - val_Interspace: 0.7704 - val_ToxicIntra_Loss: 3.0583 - val_Non_toxicIntra_Loss: 3.0601 - val_Attention_Loss: 0.1420\n",
      "Epoch 5/5\n",
      "503/503 [==============================] - 24s 48ms/step - loss: 7.7242 - accuracy: 0.5665 - Interspace: 0.7664 - ToxicIntra_Loss: 2.9914 - Non_toxicIntra_Loss: 2.9976 - Attention_Loss: 0.1430 - val_loss: 7.2706 - val_accuracy: 0.5665 - val_Interspace: 0.7643 - val_ToxicIntra_Loss: 2.7659 - val_Non_toxicIntra_Loss: 2.7719 - val_Attention_Loss: 0.1431\n"
     ]
    }
   ],
   "source": [
    "# BASE_PATH = \"/gdrive/Shareddrives/Thesis/\"\n",
    "BATCH_SIZE=16\n",
    "# BASE_PATH = \"/home/naseem_fordham/Spock-paper/Spock_HateXplain\"\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "from datetime import datetime\n",
    "import os\n",
    "l=[60]\n",
    "\n",
    "MAX_LENGTH = 30\n",
    "BATCH_SIZE = 32\n",
    "# PROJECTION_DIM =30\n",
    "VECTOR_DIM = 768\n",
    "lambda_value=2\n",
    "for PROJECTION_DIM in l:\n",
    "    spock_model1= spock_model(MAX_LENGTH, PROJECTION_DIM,lambda_value)\n",
    "    date_time= datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    BASE_PATH = f\"/home/naseem_fordham/Spock-paper/Spock_Hateoffensive/CS{PROJECTION_DIM}logs/fit/{date_time}\"\n",
    "\n",
    "    train_ds,val_ds=dataprep(PROJECTION_DIM)\n",
    "\n",
    "    # uncomment while training:\n",
    "    if not os.path.exists(BASE_PATH):\n",
    "        os.makedirs(BASE_PATH)\n",
    "        \n",
    "    logdir=f\"{BASE_PATH}/CS_model{PROJECTION_DIM}\"\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=BASE_PATH)\n",
    "\n",
    "    modelcheckpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath= f\"{BASE_PATH}/CS_{PROJECTION_DIM}.h5\",\n",
    "        \n",
    "        monitor = \"val_loss\",\n",
    "        verbose = 1,\n",
    "        save_best_only = True,\n",
    "        save_weights_only = True,\n",
    "        mode = \"auto\",\n",
    "    )\n",
    "\n",
    "    earlystopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True)\n",
    "\n",
    "    len(train_df) // BATCH_SIZE\n",
    "\n",
    "    EPOCHS = 5\n",
    "    history = spock_model1.fit(\n",
    "        train_ds,\n",
    "        steps_per_epoch = len(train_df) // BATCH_SIZE,\n",
    "        validation_data = val_ds,\n",
    "        epochs = EPOCHS,\n",
    "        callbacks = [tensorboard_callback] # we are using call back to to tensorbaord_call back which will be used later for tensorbaord\n",
    "    )\n",
    "\n",
    "\n",
    "    with open(f\"{BASE_PATH}/training_history{PROJECTION_DIM}.pkl\",\"wb\") as hist:\n",
    "      pickle.dump(history.history,hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Model and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMMAND      PID           USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
      "tensorboa 148692 naseem_fordham   11u  IPv4 1123980      0t0  TCP localhost:x11-6 (LISTEN)\n"
     ]
    }
   ],
   "source": [
    "##incase the port is already using, we have to kill it forst\n",
    "!lsof -i :6006\n",
    "!kill 148692\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-16376b1e1df4eed4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-16376b1e1df4eed4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#laod the tensor board with passing the base path. Note incase of runing on VPN, I need to \n",
    "# http://192.168.1.206:8000/user/naseem_fordham/proxy/6006/ where 6006 is the local host port\n",
    "%tensorboard --logdir $BASE_PATH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#accuracy plots\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot(history,path):\n",
    "    # Create a new figure for the combined plot\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Plot accuracy on the first subplot\n",
    "    axs[0].plot(history['accuracy'])\n",
    "    axs[0].plot(history['val_accuracy'])\n",
    "    axs[0].set_title('Model Accuracy', fontsize=12)\n",
    "    axs[0].set_ylim(0, 1, 0.1)\n",
    "    axs[0].set_ylabel('Accuracy', fontsize=12)\n",
    "    axs[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axs[0].legend(['Train', 'Validation'], loc='upper left', fontsize=12)\n",
    "    \n",
    "    # Plot loss on the second subplot\n",
    "\n",
    "\n",
    "    axs[1].plot(history['loss'])\n",
    "    axs[1].plot(history['val_loss'])\n",
    "\n",
    "    # axs[1].plot(history['ToxicIntra_Loss'])\n",
    "    # axs[1].plot(history['Non_toxicIntra_Loss'])\n",
    "    axs[1].plot(history['Interspace'])\n",
    " \n",
    "\n",
    "    axs[1].set_title('Model Loss', fontsize=12)\n",
    "    axs[1].set_ylim(0, 15, 1)\n",
    "    axs[1].set_ylabel('Loss', fontsize=12)\n",
    "    axs[1].set_xlabel('Epoch', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','offensive_normal_loss','posStdDevLoss','norStdDevLoss'], loc='upper left', fontsize=12)\n",
    "    # axs[1].legend(['Train', 'Validation','offensive_normal_loss'], loc='upper left', fontsize=12)\n",
    "    \n",
    "    # axs[1].legend(['Train', 'Validation','ToxicIntra_Loss','Non_toxicIntra_Loss'], loc='upper left', fontsize=12)\n",
    "    axs[1].legend(['Train', 'Validation','interspace'], loc='upper left', fontsize=12)\n",
    "\n",
    "    # axs[1].legend(['Train', 'Validation','ToxicIntra_Loss','Non_toxicIntra_Loss','interspace'], loc='upper left', fontsize=12)\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    # Adjust spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "    # Save the combined plot as a single image\n",
    "    plt.savefig(path, dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model laoding from directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert sigmoid outputs to labels\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def predictionLabels(i):\n",
    "    return np.where(i < 0.5, 0.0, 1.0)\n",
    "\n",
    "    \n",
    "    \n",
    "    # return np.argmax(i, axis=1)\n",
    "\n",
    "\n",
    "pattern = r\"_([0-9]+)$\"\n",
    "\n",
    "\n",
    "getLabels = np.vectorize(predictionLabels)\n",
    "# predictions = model.predict(test_ds)\n",
    "# predictedLabels = getLabels(predictions)\n",
    "\n",
    "BASE_PATH = f\"/home/naseem_fordham/Spock-paper/Spock_Hateoffensive/\"\n",
    "\n",
    "accuracy=[]\n",
    "# Iterate over subdirectories\n",
    "for folder_name in os.listdir(BASE_PATH):\n",
    "    folder_path = os.path.join(BASE_PATH, folder_name)\n",
    "\n",
    "    if os.path.isdir(folder_path):\n",
    "        match = re.search(pattern, folder_name)\n",
    "        if match:\n",
    "            model_number = match.group(1)\n",
    "            # print(folder_path)\n",
    "            spock_model2 = spock_model(MAX_LENGTH, int(model_number))\n",
    "            model_filename = os.path.join(folder_path, f\"CS_{model_number}.h5\")\n",
    "            # print(model_filename)\n",
    "\n",
    "            if os.path.exists(model_filename):\n",
    "                spock_model2.load_weights(model_filename)\n",
    "                \n",
    "                history=np.load(f\"{folder_path}/training_history{model_number}.pkl\",allow_pickle=True)\n",
    "                accuracy.append(history['val_accuracy'][-1])\n",
    "                \n",
    "                # print(f\"Loaded model from {model_filename,model_number}\")\n",
    "                train_ds, val_ds = dataprep(int(model_number))\n",
    "\n",
    "                # Calculate the confusion matrix\n",
    "                predictions = spock_model2.predict(val_ds)\n",
    "                predictedLabels = predictionLabels(predictions)\n",
    "                cm = confusion_matrix(val_df['class'].values, predictedLabels)\n",
    "\n",
    "                # Calculate the confusion matrix as percentages\n",
    "                cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "                # Create a ConfusionMatrixDisplay for the percentage confusion matrix\n",
    "                disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['Toxic', 'Non-Toxic'])\n",
    "\n",
    "                # Calculate the classification report\n",
    "                clf_report = classification_report(val_df['class'],\n",
    "                                                   predictedLabels,\n",
    "                                                   target_names=['Toxic', 'Non-Toxic'],\n",
    "                                                   output_dict=True)\n",
    "\n",
    "                # Create a new figure for the combined plot\n",
    "                fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "                # Plot the confusion matrix as percentages on the left\n",
    "                disp.plot(cmap=plt.cm.Blues, values_format=\".2f\", ax=axs[0])\n",
    "                axs[0].set_title(f'Confusion Matrix of CS_{model_number}')\n",
    "\n",
    "                # Plot the classification report as a heatmap on the right\n",
    "                sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True, ax=axs[1])\n",
    "                axs[1].set_title(f'Classification Report of CS_{model_number}')\n",
    "\n",
    "                # Adjust spacing between subplots\n",
    "                plt.subplots_adjust(wspace=0.5)\n",
    "                \n",
    "                \n",
    "                           # Save the combined plot as a single image\n",
    "                plt.savefig(f'{folder_path}/combined_CS_{model_number}.png')\n",
    "                plot(history,f'{folder_path}/Acc_loss{model_number}.png')\n",
    "\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Weights and Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "U7gwzlktUtH9",
    "outputId": "56a7955b-b7bf-49f7-c6b5-135b4bcb0926"
   },
   "outputs": [],
   "source": [
    "# UNCOMMENT THIS CELL AFTER MODEL TRAINING\n",
    "\n",
    "# save model history\n",
    "\n",
    "with open(f\"{BASE_PATH}/training_historyV4.pkl\",\"wb\") as hist:\n",
    "  pickle.dump(history.history,hist)\n",
    "\n",
    "# history=np.save(f\"/home/naseem_fordham/Hate_Xplain/history/C_loss_history_{PROJECTION_DIM}.npy\",history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_PATH = \"/home/naseem_fordham/Spock-paper/Spock_HateXplain\"\n",
    "model.load_weights(f\"{BASE_PATH}/test3.h5\")\n",
    "history=np.load(f\"{BASE_PATH}/training_historyV4.pkl\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23gCGD8ZeJfE",
    "outputId": "43e84bd0-3285-47e0-9b26-f5ed8ba6102f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # BASE_PATH='/home/naseem_fordham/Spock-paper/'\n",
    "# model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "# history=np.load(f\"{BASE_PATH}/training_historyV4.pkl\",allow_pickle=True)\n",
    "# history\n",
    "# import pickle\n",
    "\n",
    "# with open('/home/naseem_fordham/Spock-paper/Random_w/Model/training_historyV4.pkl', 'rb') as f:\n",
    "#     loaded_data = np.load(f,allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3kEUFa9eRfk"
   },
   "outputs": [],
   "source": [
    "# prepare test data for evaluation:\n",
    "test_gen   = dataset(test_df[\"tweet\"].values,test_df[\"class\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer, projection_dim=PROJECTION_DIM, val = True)\n",
    "test_ds = tf.data.Dataset.from_generator(test_gen,\n",
    "                                            output_signature = \n",
    "                                           ({\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32)},\n",
    "                                            tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3VcYiveLe-Ki"
   },
   "outputs": [],
   "source": [
    "# convert sigmoid outputs to labels\n",
    "def predictionLabels(i):\n",
    "     return np.argmax(i, axis=1)\n",
    "\n",
    "  # if i < 0.5:\n",
    "  #   return 0.0\n",
    "  # else:\n",
    "  #   return 1.0\n",
    "\n",
    "# getLabels = np.vectorize(predictionLabels)\n",
    "predictions = model.predict(test_ds)\n",
    "predictedLabels = predictionLabels(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictedLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-Cv6nLJsSsL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "predictedLabels = predictionLabels(predictions)\n",
    "\n",
    "confusion_matrix(test_df['class'].values, predictedLabels)\n",
    "ConfusionMatrixDisplay.from_predictions(test_df['class'].values, predictedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(test_df['class'].values, predictedLabels)\n",
    "\n",
    "# Calculate the confusion matrix as percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Create a ConfusionMatrixDisplay for the percentage confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_percentage, display_labels=['0','1','2'])  # You should define class_labels\n",
    "\n",
    "# Plot the confusion matrix as percentages\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\".2f\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nIV_XQ00gUYz",
    "outputId": "a28ee2c7-3d22-4fa8-a4fc-16b73454c70b"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# print(classification_report(y_test, predictedLabels))\n",
    "clf_report = classification_report(test_df['class'],\n",
    "                                   predictedLabels,\n",
    "                                   \n",
    "                                   target_names=[0,1,2],\n",
    "                                   output_dict=True)\n",
    "\n",
    "\n",
    "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-1xVwjAJgVrt",
    "outputId": "2b7f24a8-291e-4f8b-a5a3-cf9d89f07aaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(history['accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('model accuracy',fontdict = {'fontsize' : 12})\n",
    "plt.ylim(0,1,0.1)\n",
    "\n",
    "plt.ylabel('accuracy',fontdict = {'fontsize' : 12})\n",
    "plt.xlabel('epoch',{'fontsize' : 12})\n",
    "# plt.ylim(0, ,0.05)\n",
    "plt.legend(['train', 'val'], loc='upper left',fontsize=12)\n",
    "plt.title('Training vs Validation accuracy')\n",
    "# display(plt.show())\n",
    "# plt.show()\n",
    "\n",
    "# plt.savefig(f\"/home/naseem_fordham/Hate_Xplain//acc.png\",dpi=300)\n",
    "# plt.savefig(f\"/home/naseem_fordham/Hate_Xplain/Plots/plots{PROJECTION_DIM}/accu_{PROJECTION_DIM}.png\",dpi=300)\n",
    "\n",
    "#skip: plt.savefig(\"/gdrive/Shareddrives/Thesis/Results_for_thesis/spock_xhate_acc.png\",dpi=300)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "# plt.yticks(np.arange(0,1,step=.1))\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.ylim(0,3,0.1)\n",
    "\n",
    "# plt.title('Training loss vs Validation Loss',fontdict = {'fontsize' : 12})\n",
    "plt.ylabel('loss',fontdict = {'fontsize' : 12})\n",
    "plt.xlabel('epoch',fontdict = {'fontsize' : 12})\n",
    "plt.legend(['train', 'val'], loc='upper left',fontsize=12)\n",
    "plt.title('Training vs Validation loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime Explainibity\n",
    "In this part we are using LIME method to understnd how our model is predicting each word in the senetcen and labeled it as per classification## In this part we are using LIME method to understnd how our model is predicting each word in the senetcen and labeled it as per classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in train_ds.take(1):\n",
    "#   temp = ele\n",
    "# temp_iids = temp[0][\"input_ids\"]\n",
    "# # temp_mask = temp[0][\"attention_masks\"]\n",
    "# temp_iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# laoding data set and performning cleaning to ready for feed funtion,\n",
    "# here we have assigned a tem class to our data set\n",
    "df_test=pd.read_csv('/home/naseem_fordham/Spock-paper/test.txt',sep='/n', header=None,engine='python')\n",
    "df_test = df_test.rename(columns={0: 'tweet'})\n",
    "df_test\n",
    "\n",
    "df_test[\"tweet\"] = df_test[\"tweet\"].apply(lambda x : text_preprocessing(x))\n",
    "df_test['class']=1\n",
    "df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create generators for train and validation\n",
    "BATCH_SIZE = 32\n",
    "# make sure batch size complies with total data set\n",
    "lime_gen = dataset(df_test[\"tweet\"].values,df_test[\"class\"].values,max_length = MAX_LENGTH, tokenizer = tokenizer,projection_dim=PROJECTION_DIM)\n",
    "\n",
    "# create tensorflow dataloaders from generators\n",
    "lime_ds = tf.data.Dataset.from_generator(lime_gen,\n",
    "                                            output_signature =\n",
    "                                           ( {\"input_ids\" : tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32 ),\"attention_masks\":tf.TensorSpec(shape = (MAX_LENGTH,), dtype = tf.int32),\"space\":tf.TensorSpec(shape = (PROJECTION_DIM,), dtype = tf.int32)},\n",
    "                                            tf.TensorSpec(shape = (), dtype = (tf.float32)))).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict function which will be use later for each text in sentence\n",
    "def predict_fun(x):\n",
    "    return model.predict(lime_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.predict(lime_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in lime_ds.take(1):\n",
    "#     t=ele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# x=df_test['tweet'][0]\n",
    "# print(len(x))\n",
    "\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=['non_hate','hate'])\n",
    "# exp=explainer.explain_instance(x, predict_fun, num_features=90, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(df_test['tweet'].iloc[i].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implementing LIME on each sentence\n",
    "\"\"\"Interpretability: If you want highly interpretable explanations that focus on the most salient \n",
    "words or terms, you may choose a lower num_features value.\n",
    "\n",
    "Comprehensiveness: If you want a more comprehensive understanding of why the model made a particular\n",
    "prediction and are willing to explore a larger number of words or terms, you may choose a higher num_features value.\"\"\"\n",
    "\n",
    "\n",
    "''' 0 - hate speech 1 - offensive language 2 - neither'''\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "for i in range(1,10):\n",
    "\n",
    "    x=df_test['tweet'].iloc[i]\n",
    "    # num=len(df_test['tweet'].iloc[i].split())\n",
    "    \n",
    "\n",
    "    explainer = LimeTextExplainer(class_names=['hate','offensive','normal'])\n",
    "    exp=explainer.explain_instance(x, predict_fun, num_features=6, labels=(0,1), num_samples=10, distance_metric='cosine')\n",
    "    exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime EXplaniation Alternative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ele in lime_ds.take(0):\n",
    "#   temp = ele\n",
    "# temp_iids = temp[0]\n",
    "# # # temp_mask = temp[0][\"attention_masks\"]\n",
    "# temp_iids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_res= list()\n",
    "# for tweet in df_test['tweet']:\n",
    "#   tweet = text_preprocessing(tweet)\n",
    "#   test_res.append(tweet)\n",
    "#     # print(tweet)\n",
    "\n",
    "# df_test['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96kydpg1iWwm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Input_ids=Inputs_test.reshape((Inputs_test.shape[0],1,Inputs_test.shape[1]))\n",
    "# # bertModel = TFAutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "# # tokenizer \n",
    "# '''In this part we are creating the bert inputs for our model and pass it to the model to predicts the class. \n",
    "# Later on we pass this predict model to LIME to underrstand which part of text is more relavent as per our model prediction'''\n",
    "\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# bmodel = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# import torch\n",
    "# def predict(x):\n",
    "#     encoded = tokenizer(\n",
    "#     text=df_test['tweet'].tolist(),  # the sentence to be encoded\n",
    "#     add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "#     max_length = 45,  # maximum length of a sentence\n",
    "#     padding='max_length',  # Add [PAD]s\n",
    "#     return_attention_mask = True,  # Generate the attention mask\n",
    "#     return_tensors = 'pt',  # ask the function to return PyTorch tensors\n",
    "\n",
    "#   )\n",
    "#   # print(encoded)\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         outputs = bmodel(**encoded)\n",
    "\n",
    "#         # Evaluating the model will return a different number of objects based on \n",
    "#         # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "#         # becase we set `output_hidden_states = True`, the third item will be the \n",
    "#         # hidden states from all layers. See the documentation for more details:\n",
    "#         # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "#         # hidden_states = outputs[2]\n",
    "#         # violent_hidden_states = violent_outputs[2]\n",
    "\n",
    "#         last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "#     # print(last_hidden_states)\n",
    "\n",
    "#     x_test=last_hidden_states.numpy()\n",
    "#     # print(x_test.shape)\n",
    "#     Inputs_test=encoded['input_ids']\n",
    "#     # print(Inputs_test.shape)\n",
    "#     Inputs_test=Inputs_test.reshape((Inputs_test.shape[0],1,Inputs_test.shape[1])).numpy()\n",
    "#     print(Inputs_test.shape)\n",
    "\n",
    "\n",
    "#     # print(x_test.shape,Inputs_test.shape)\n",
    "#     embedding_test=embedding_index[0].reshape(embedding_index[0].shape[0],1)\n",
    "#     # embedding_test=embedding_index[:30]\n",
    "#   # embedding_test=embedding_index[:30].reshape(30,embedding_index[:30].shape[1],1)\n",
    "#   # embedding_test=embedding_index[:10].reshape(10,embedding_index.shape[1])\n",
    "#   # return model.predict([x_test,Inputs_test,embedding_test])\n",
    "  \n",
    "#     # print(embedding_test.shape)\n",
    "#     print(x_test.shape,Inputs_test.shape,embedding_test.shape)\n",
    "#     return np.array([[float(1-x), float (x)] for x in model.predict(lime_ds)])\n",
    "#     # return last_hidden_states\n",
    "# # model.predict([x_train,Input_ids,embedding_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def return_embedding_index(count):\n",
    "  \n",
    "#   embedding_index=np.array([i for i in range(count)])\n",
    "#   # embeding_index=np.array([[0,1,2]])\n",
    "#   embeding_index=np.ravel(embedding_index)\n",
    "\n",
    "#   embedding_index=np.tile(embedding_index,(len(df_test),1,))\n",
    "#   # print(embedding_index.shape, type(embeding_index))\n",
    "#   return embedding_index\n",
    "\n",
    "# embedding_index = return_embedding_index(PROJECTION_DIM)\n",
    "# embedding_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "# x=df_test['tweet'][0]\n",
    "# print(len(x))\n",
    "\n",
    "\n",
    "# explainer = LimeTextExplainer(class_names=['peace','offensive'])\n",
    "# exp=explainer.explain_instance(x, predict, num_features=60, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "# #num of sample must be same as length of the data set \n",
    "# exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from lime.lime_text import LimeTextExplainer\n",
    "# for i in range(10):\n",
    "\n",
    "#     x=df_test['tweet'].iloc[i]\n",
    "\n",
    "#     explainer = LimeTextExplainer(class_names=['peace','offensive'])\n",
    "#     exp=explainer.explain_instance(x, predict, num_features=30, labels=(1,), num_samples=9, distance_metric='cosine')\n",
    "#     #num of sample must be same as length of the data set \n",
    "#     exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Concept Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "\n",
    "\n",
    "hate_layer = model.get_layer('hate_embedding')\n",
    "hate_embedding = hate_layer.get_weights()\n",
    "# positive_weights=positive_weights[0].T\n",
    "\n",
    "\n",
    "offensive_layer = model.get_layer('offensive_embedding')\n",
    "offensive_embedding = offensive_layer.get_weights()\n",
    "\n",
    "\n",
    "normal_layer = model.get_layer('normal_embedding')\n",
    "normal_embedding = normal_layer.get_weights()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# positive_embedding = model.get_layer('positive_embedding')  # Replace with the name of your layer\n",
    "# # Get the weights of the specific layer\n",
    "# positive_embedding = specific_layer.get_weights()\n",
    "# positive_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # model.load_weights(f\"{BASE_PATH}/Modeltest1.h5\")\n",
    "# negative_embedding = model.get_layer('negative_embedding')  # Replace with the name of your layer\n",
    "# # Get the weights of the specific layer\n",
    "# negative_embedding = specific_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Assuming you have two weight vectors of shape (10, 768)\n",
    "\n",
    "\n",
    "\n",
    "# # Combine the two weight vectors into one array\n",
    "# combined_weight_vectors = np.vstack([offensive_embedding[0], hate_embedding[0],normal_embedding[0]])\n",
    "# tsne = TSNE(n_components=2, perplexity=2, early_exaggeration=12.0, learning_rate=20.0, n_iter=1000)\n",
    "# # Compute t-SNE embeddings\n",
    "# # tsne = TSNE(n_components=2, random_state=42)\n",
    "# tsne_embeddings = tsne.fit_transform(combined_weight_vectors)\n",
    "\n",
    "# # Separate the t-SNE embeddings for the two weight vectors\n",
    "# tsne_embeddings1 = tsne_embeddings[:25]  # First weight vector\n",
    "# tsne_embeddings2 = tsne_embeddings[25:50]  # Second weight vector\n",
    "# tsne_embeddings3 = tsne_embeddings[50:] \n",
    "\n",
    "# # Create a scatter plot for the t-SNE embeddings\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.scatter(tsne_embeddings1[:, 0], tsne_embeddings1[:, 1], label='hate_embedding', s=5)\n",
    "# plt.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], label='offensive_embedding', s=5)\n",
    "# plt.scatter(tsne_embeddings3[:, 0], tsne_embeddings3[:, 1], label='offensive_embedding', s=5)\n",
    "# # plt.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], label='normal_embedding', s=5)\n",
    "\n",
    "# plt.xlabel('t-SNE Dimension 1')\n",
    "# plt.ylabel('t-SNE Dimension 2')\n",
    "# plt.legend()\n",
    "# plt.title('t-SNE Visualization of Weight Vectors')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Import the 3D plotting module\n",
    "\n",
    "# Assuming you have three weight vectors of shape (10, 768)\n",
    "\n",
    "# Combine the three weight vectors into one array\n",
    "combined_weight_vectors = np.vstack([hate_embedding[0], offensive_embedding[0], normal_embedding[0]])\n",
    "tsne = TSNE(n_components=3, perplexity=50, early_exaggeration=12.0, learning_rate=50.0, n_iter=10000)\n",
    "\n",
    "# Compute t-SNE embeddings\n",
    "tsne_embeddings = tsne.fit_transform(combined_weight_vectors)\n",
    "\n",
    "# Separate the t-SNE embeddings for the three weight vectors\n",
    "tsne_embeddings1 = tsne_embeddings[:25]        # First weight vector (hate)\n",
    "tsne_embeddings2 = tsne_embeddings[25:50]      # Second weight vector (offensive)\n",
    "tsne_embeddings3 = tsne_embeddings[50:]        # Third weight vector (normal)\n",
    "\n",
    "# Create a 3D scatter plot for the t-SNE embeddings\n",
    "fig = plt.figure(figsize=(8, 12))\n",
    "ax = fig.add_subplot(111, projection='3d')  # Create a 3D axis\n",
    "\n",
    "ax.scatter(tsne_embeddings1[:, 0], tsne_embeddings1[:, 1], tsne_embeddings1[:, 2], label='hate_embedding', s=5)\n",
    "ax.scatter(tsne_embeddings2[:, 0], tsne_embeddings2[:, 1], tsne_embeddings2[:, 2], label='offensive_embedding', s=5)\n",
    "ax.scatter(tsne_embeddings3[:, 0], tsne_embeddings3[:, 1], tsne_embeddings3[:, 2], label='normal_embedding', s=5)\n",
    "\n",
    "ax.set_xlabel('t-SNE Dimension 1')\n",
    "ax.set_ylabel('t-SNE Dimension 2')\n",
    "ax.set_zlabel('t-SNE Dimension 3')\n",
    "plt.legend()\n",
    "plt.title('3D t-SNE Visualization of Weight Vectors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyMciCgoRuYPP4D87bGoAjIQ",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06285d669e92494192637cb3ee5a40f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f14c359d92748268810099e6cdd1fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06285d669e92494192637cb3ee5a40f4",
      "placeholder": "​",
      "style": "IPY_MODEL_209ee3e0949b446b8c58c57989065c5a",
      "value": " 232k/232k [00:00&lt;00:00, 2.84MB/s]"
     }
    },
    "123641d1426541fba838576dff7f6082": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "17ae300ebf634778862bc211cb432eef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a51f1ae4e3bd4563be3eb7c04dec7a60",
      "placeholder": "​",
      "style": "IPY_MODEL_c7586ac9b41c4e75b02a6c076a458686",
      "value": "Downloading (…)/main/tokenizer.json: 100%"
     }
    },
    "18e134c7af5d45baa952ccf06f96f3d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f1d5a79d7ec4e42add7775fa925b187",
      "placeholder": "​",
      "style": "IPY_MODEL_e89d668a4fb541ec8d75d171bf899869",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "1cf66f2a8c5f49ce98d59dae5186298d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfd44792f624499b87bd768836016e88",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ae841edad05b4ef9b4308308d6683fa3",
      "value": 570
     }
    },
    "1ec35f8bfadb40968f777ab7bbb55184": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b0c918326174bc4b80585a52ac33e32",
      "placeholder": "​",
      "style": "IPY_MODEL_e38ea829111b4065bad8ad4a4927bc39",
      "value": " 466k/466k [00:00&lt;00:00, 8.67MB/s]"
     }
    },
    "2024092105904b418c984aae9f4118bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f0a4e1b4929448a8b0a25b202271a40",
      "placeholder": "​",
      "style": "IPY_MODEL_ac93c61a19c0474994803853194d2aa8",
      "value": " 28.0/28.0 [00:00&lt;00:00, 584B/s]"
     }
    },
    "209ee3e0949b446b8c58c57989065c5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21bf2e03eac8419fa693628ab2cef02d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_430a9d1768614e0596960d2a3d15d69e",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_909ae03e117345f7a4b53f3045e090b7",
      "value": 231508
     }
    },
    "274875a4aa6047c9903ae3065a5d85c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31914a14cfa243388f43a02da4db24b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3258d106659040dfb7ffea47c017ed38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34bbd1edf06c4a9194bd27eaeeee32b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34e574772e8b4f81bc7e02e8ebaeb258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3258d106659040dfb7ffea47c017ed38",
      "placeholder": "​",
      "style": "IPY_MODEL_f9a2caba063b4a4f98ad258044d012fb",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "3c294ab0d9a648f39ea3f3fb7dd08c3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430a9d1768614e0596960d2a3d15d69e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4914d10c0f354e178de66dc11449e26a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7998e50af804d66b6af0f26b5588255",
      "placeholder": "​",
      "style": "IPY_MODEL_4fa52eecbe8a4ba38ef969fd1cf48cfd",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "4cc5655f9bdb42bca5d80e2849e8cd2b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f0a4e1b4929448a8b0a25b202271a40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f1d5a79d7ec4e42add7775fa925b187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fa52eecbe8a4ba38ef969fd1cf48cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50859aa086814457bcab249b35d486a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "570b9a872e614e0eab6618f306be7306": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_34e574772e8b4f81bc7e02e8ebaeb258",
       "IPY_MODEL_1cf66f2a8c5f49ce98d59dae5186298d",
       "IPY_MODEL_71f100b04c964a1bbde06c537f483ed7"
      ],
      "layout": "IPY_MODEL_9e1caf8b23fb4eb1976f808269d1dd3e"
     }
    },
    "5a072e1f73624ea5aa35e7e18af17f50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a0c04349bae44f4a7130463ded826d1",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f11959bab964aad822250b6e6853cb8",
      "value": 466062
     }
    },
    "672e978f9b524c5784553abd8cc91507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17ae300ebf634778862bc211cb432eef",
       "IPY_MODEL_5a072e1f73624ea5aa35e7e18af17f50",
       "IPY_MODEL_1ec35f8bfadb40968f777ab7bbb55184"
      ],
      "layout": "IPY_MODEL_274875a4aa6047c9903ae3065a5d85c2"
     }
    },
    "69d90bdca5174dfb91f5cf124884095e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71d0c2b02f0c4a609477bc31aa880938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c12c857f159443f1b2a661fcd7afa002",
       "IPY_MODEL_989933f9c84a47d4b64d5b5441a1f492",
       "IPY_MODEL_2024092105904b418c984aae9f4118bf"
      ],
      "layout": "IPY_MODEL_4cc5655f9bdb42bca5d80e2849e8cd2b"
     }
    },
    "71f100b04c964a1bbde06c537f483ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34bbd1edf06c4a9194bd27eaeeee32b2",
      "placeholder": "​",
      "style": "IPY_MODEL_ea850e74cb6a4121a456578b29ce7955",
      "value": " 570/570 [00:00&lt;00:00, 5.04kB/s]"
     }
    },
    "8a0c04349bae44f4a7130463ded826d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "909ae03e117345f7a4b53f3045e090b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "989933f9c84a47d4b64d5b5441a1f492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9910be9c8b7b4188936721e958ca15c5",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50859aa086814457bcab249b35d486a8",
      "value": 28
     }
    },
    "9910be9c8b7b4188936721e958ca15c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b0c918326174bc4b80585a52ac33e32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e1caf8b23fb4eb1976f808269d1dd3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f11959bab964aad822250b6e6853cb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a51f1ae4e3bd4563be3eb7c04dec7a60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac93c61a19c0474994803853194d2aa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae841edad05b4ef9b4308308d6683fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5516712d5304670a05ec871eb5896a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c12c857f159443f1b2a661fcd7afa002": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd56d3ae17774e5496a7fdcbcb57b874",
      "placeholder": "​",
      "style": "IPY_MODEL_b5516712d5304670a05ec871eb5896a4",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "c7586ac9b41c4e75b02a6c076a458686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfe933364a3147368660f5463f1e5a29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d69dfd21bce04204b3220b71b4d4a968": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4914d10c0f354e178de66dc11449e26a",
       "IPY_MODEL_f554ec9fe80a408680aa7b0a1c6837ac",
       "IPY_MODEL_f4ec333b7c654876a6caad010e88c203"
      ],
      "layout": "IPY_MODEL_cfe933364a3147368660f5463f1e5a29"
     }
    },
    "dfd44792f624499b87bd768836016e88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e38ea829111b4065bad8ad4a4927bc39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e89d668a4fb541ec8d75d171bf899869": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e99b3d05437f4cdf9e1700e3cf466b34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea850e74cb6a4121a456578b29ce7955": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ee12049f5a9c4505b9769a4ff9c36477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_18e134c7af5d45baa952ccf06f96f3d8",
       "IPY_MODEL_21bf2e03eac8419fa693628ab2cef02d",
       "IPY_MODEL_0f14c359d92748268810099e6cdd1fc3"
      ],
      "layout": "IPY_MODEL_e99b3d05437f4cdf9e1700e3cf466b34"
     }
    },
    "f4ec333b7c654876a6caad010e88c203": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69d90bdca5174dfb91f5cf124884095e",
      "placeholder": "​",
      "style": "IPY_MODEL_123641d1426541fba838576dff7f6082",
      "value": " 440M/440M [00:06&lt;00:00, 121MB/s]"
     }
    },
    "f554ec9fe80a408680aa7b0a1c6837ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c294ab0d9a648f39ea3f3fb7dd08c3c",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_31914a14cfa243388f43a02da4db24b6",
      "value": 440449768
     }
    },
    "f7998e50af804d66b6af0f26b5588255": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9a2caba063b4a4f98ad258044d012fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd56d3ae17774e5496a7fdcbcb57b874": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
